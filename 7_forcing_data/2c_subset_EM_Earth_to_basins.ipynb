{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d620cd8",
   "metadata": {},
   "source": [
    "# Subset EM-Earth data to basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6403cb47-d450-4699-83b6-38eaa7e483fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "import python_cs_functions as cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73793dff",
   "metadata": {},
   "source": [
    "### Config handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd4a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where the config file can be found\n",
    "config_file = '../0_config/config.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4855e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the required info from the config file\n",
    "data_path = cs.read_from_config(config_file,'data_path')\n",
    "\n",
    "# CAMELS-spat metadata\n",
    "cs_meta_path = cs.read_from_config(config_file,'cs_basin_path')\n",
    "cs_meta_name = cs.read_from_config(config_file,'cs_meta_name')\n",
    "cs_unusable_name = cs.read_from_config(config_file,'cs_unusable_name')\n",
    "\n",
    "# Basin folder\n",
    "cs_basin_folder = cs.read_from_config(config_file, 'cs_basin_path')\n",
    "basins_path = Path(data_path) / cs_basin_folder\n",
    "\n",
    "# Temporary download path\n",
    "temp_folder = Path( cs.read_from_config(config_file, 'temp_path') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6f7d7",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c6e1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMELS-spat metadata file\n",
    "cs_meta_path = Path(data_path) / cs_meta_path\n",
    "cs_meta = pd.read_csv(cs_meta_path / cs_meta_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9374522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open list of unusable stations; Enforce reading IDs as string to keep leading 0's\n",
    "cs_unusable = pd.read_csv(cs_meta_path / cs_unusable_name, dtype={'Station_id': object})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98bc25",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ba21d5-e20f-473b-bde6-fdf58a3480f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ERA5 files\n",
    "em_earth_fold = temp_folder / 'EM_Earth_v1' / 'deterministic_hourly' / 'merged'\n",
    "em_earth_files = sorted(glob.glob(str(em_earth_fold/'*.nc'))) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d076fb86-d457-421a-a225-45c21b2eafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_message = f'\\n!!! CHECK DEBUGGING STATUS: \\n- Testing 1 file \\n- Testing 1 basin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6273a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!! CHECK DEBUGGING STATUS: \n",
      "- Testing 1 file \n",
      "- Testing 1 basin\n",
      "--- Now running basin 0. CAN_01AD002\n",
      "    Basin coordinates:            [-70.43208333  45.98541667 -68.07125     47.83791667]\n",
      "    EM-Earth subset coordinates: [47.85/-70.45/45.95/-68.05]\n",
      "    Flow obs unavailable:         ['iv', nan]\n",
      "    Download times:               ['1950-01-01', '2020-12-31']\n",
      "\n",
      "!!! CHECK DEBUGGING STATUS: \n",
      "- Testing 1 file \n",
      "- Testing 1 basin\n"
     ]
    }
   ],
   "source": [
    "print(debug_message)\n",
    "for ix,row in cs_meta.iterrows():\n",
    "\n",
    "    # DEBUGGING\n",
    "    if ix != 0: continue\n",
    "    \n",
    "    # Get shapefile path to determine download coordinates, and forcing destination path\n",
    "    basin_id, shp_lump_path, shp_dist_path, _, _ = cs.prepare_delineation_outputs(cs_meta, ix, Path(data_path)/cs_basin_folder)\n",
    "    raw_fold, _, _ = cs.prepare_forcing_outputs(cs_meta, ix, Path(data_path)/cs_basin_folder) # Returns folders only, not file names\n",
    "    print('--- Now running basin {}. {}'.format(ix, basin_id))\n",
    "    \n",
    "    # From shapefile, get bounding coordinates. Then determine download coordinates from those\n",
    "    bounds = cs.find_shapefile_bounds(shp_lump_path)\n",
    "    coords_eme, _, _ = cs.find_download_coords_from_bounds(bounds, target='EM-Earth')\n",
    "    \n",
    "    # Check if we need to run downloads for this station at all\n",
    "    missing = cs.flow_obs_unavailable(cs_unusable, row.Country, row.Station_id)\n",
    "    if 'iv' in missing and 'dv' in missing: \n",
    "        continue # with next station, because we have no observations at all for this station\n",
    "\n",
    "    # From meta-data, get download period\n",
    "    times_flow = cs.find_flow_obs_times_from_metadata(row, missing)\n",
    "    times_era5 = cs.round_flow_obs_to_days(times_flow)\n",
    "    start_date = datetime.strptime(times_era5[0], '%Y-%m-%d')\n",
    "    final_date = datetime.strptime(times_era5[1], '%Y-%m-%d')\n",
    "    \n",
    "    print(f'    Basin coordinates:            {bounds}')\n",
    "    print(f'    EM-Earth subset coordinates: [{coords_eme}]')\n",
    "    print(f'    Flow obs unavailable:         {missing}')\n",
    "    print(f'    Download times:               {times_era5}')\n",
    "\n",
    "    # Convert start and end dates into two lists of start and end dates, that we'll iterate over\n",
    "    date_list,_ = cs.convert_start_and_end_dates_to_era5_download_lists(start_date,final_date) # not the cleanest but this lets us reuse old code\n",
    "    subset_strings = [date_obj.strftime(\"%Y-%m\") for date_obj in date_list] # convert datetime objects to yyyy-mm strings\n",
    "\n",
    "    # Subset the data files\n",
    "    infiles = [file for file in em_earth_files if any(subset_string in file for subset_string in subset_strings)]\n",
    "    \n",
    "    for infile in infiles:\n",
    "        if os.path.exists(infile):\n",
    "            file_name = os.path.basename(infile).replace('deterministic_hourly_NorthAmerica_','') # Make the name more similar to ERA5_YYYY-MM.nc\n",
    "            outfile = raw_fold/file_name\n",
    "            if not os.path.exists(outfile):\n",
    "                cs.extract_ERA5_subset(infile,outfile,coords_eme)\n",
    "        else:\n",
    "            print(f'    ERROR: source file {infile} not found.')\n",
    "    \n",
    "    # Create a figure to check if we actually cover the right domain with this\n",
    "    fig_file = raw_fold.parent / f'{row.Country}_{row.Station_id}_em_earth_coverage.png'\n",
    "    cs.compare_forcing_data_and_shape_extents(fig_file, outfile, shp_lump_path, nc_var='tmean', nc_time=0)\n",
    "\n",
    "print(debug_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133d060-1190-440b-9809-70c3a10e06c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camels-spat-env",
   "language": "python",
   "name": "camels-spat-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
