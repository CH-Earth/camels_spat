{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d620cd8",
   "metadata": {},
   "source": [
    "# Subset EM-Earth data to basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6403cb47-d450-4699-83b6-38eaa7e483fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "import python_cs_functions as cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73793dff",
   "metadata": {},
   "source": [
    "### Config handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd4a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where the config file can be found\n",
    "config_file = '../0_config/config.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4855e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the required info from the config file\n",
    "data_path = cs.read_from_config(config_file,'data_path')\n",
    "\n",
    "# CAMELS-spat metadata\n",
    "cs_meta_path = cs.read_from_config(config_file,'cs_basin_path')\n",
    "cs_meta_name = cs.read_from_config(config_file,'cs_meta_name')\n",
    "cs_unusable_name = cs.read_from_config(config_file,'cs_unusable_name')\n",
    "\n",
    "# Basin folder\n",
    "cs_basin_folder = cs.read_from_config(config_file, 'cs_basin_path')\n",
    "basins_path = Path(data_path) / cs_basin_folder\n",
    "\n",
    "# Temporary download path\n",
    "temp_folder = Path( cs.read_from_config(config_file, 'temp_path') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6f7d7",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c6e1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMELS-spat metadata file\n",
    "cs_meta_path = Path(data_path) / cs_meta_path\n",
    "cs_meta = pd.read_csv(cs_meta_path / cs_meta_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9374522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open list of unusable stations; Enforce reading IDs as string to keep leading 0's\n",
    "cs_unusable = pd.read_csv(cs_meta_path / cs_unusable_name, dtype={'Station_id': object})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98bc25",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ba21d5-e20f-473b-bde6-fdf58a3480f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ERA5 files\n",
    "em_earth_fold = temp_folder / 'EM_Earth_v1' / 'deterministic_hourly' / 'merged'\n",
    "em_earth_files = sorted(glob.glob(str(em_earth_fold/'*.nc'))) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d076fb86-d457-421a-a225-45c21b2eafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_message = f'\\n!!! CHECK DEBUGGING STATUS: \\n- Testing 1 file \\n- Testing 1 basin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6273a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!! CHECK DEBUGGING STATUS: \n",
      "- Testing 1 file \n",
      "- Testing 1 basin\n",
      "--- Now running basin 0. CAN_01AD002\n",
      "    Basin coordinates:         [-70.43208333  45.98541667 -68.07125     47.83791667]\n",
      "    ERA5 download coordinates: [47.85/-70.45/45.95/-68.05]\n",
      "    Flow obs unavailable:      ['iv', nan]\n",
      "    Download times:            ['1950-01-01', '2020-12-31']\n",
      "\n",
      "!!! CHECK DEBUGGING STATUS: \n",
      "- Testing 1 file \n",
      "- Testing 1 basin\n"
     ]
    }
   ],
   "source": [
    "print(debug_message)\n",
    "for ix,row in cs_meta.iterrows():\n",
    "\n",
    "    # DEBUGGING\n",
    "    if ix != 0: continue\n",
    "    \n",
    "    # Get shapefile path to determine download coordinates, and forcing destination path\n",
    "    basin_id, shp_lump_path, shp_dist_path, _, _ = cs.prepare_delineation_outputs(cs_meta, ix, Path(data_path)/cs_basin_folder)\n",
    "    raw_fold, _, _ = cs.prepare_forcing_outputs(cs_meta, ix, Path(data_path)/cs_basin_folder) # Returns folders only, not file names\n",
    "    print('--- Now running basin {}. {}'.format(ix, basin_id))\n",
    "    \n",
    "    # From shapefile, get bounding coordinates. Then determine download coordinates from those\n",
    "    bounds = cs.find_shapefile_bounds(shp_lump_path)\n",
    "    coords_eme, _, _ = cs.find_download_coords_from_bounds(bounds, target='EM-Earth')\n",
    "    \n",
    "    # Check if we need to run downloads for this station at all\n",
    "    missing = cs.flow_obs_unavailable(cs_unusable, row.Country, row.Station_id)\n",
    "    if 'iv' in missing and 'dv' in missing: \n",
    "        continue # with next station, because we have no observations at all for this station\n",
    "\n",
    "    # From meta-data, get download period\n",
    "    times_flow = cs.find_flow_obs_times_from_metadata(row, missing)\n",
    "    times_era5 = cs.round_flow_obs_to_days(times_flow)\n",
    "    start_date = datetime.strptime(times_era5[0], '%Y-%m-%d')\n",
    "    final_date = datetime.strptime(times_era5[1], '%Y-%m-%d')\n",
    "    \n",
    "    print(f'    Basin coordinates:            {bounds}')\n",
    "    print(f'    EM-Earth subset coordinates: [{coords_eme}]')\n",
    "    print(f'    Flow obs unavailable:         {missing}')\n",
    "    print(f'    Download times:               {times_era5}')\n",
    "\n",
    "    # Convert start and end dates into two lists of start and end dates, that we'll iterate over\n",
    "    date_list,_ = cs.convert_start_and_end_dates_to_era5_download_lists(start_date,final_date) # not the cleanest but this lets us reuse old code\n",
    "    subset_strings = [date_obj.strftime(\"%Y-%m\") for date_obj in date_list] # convert datetime objects to yyyy-mm strings\n",
    "\n",
    "    # Subset the data files\n",
    "    infiles = [file for file in em_earth_files if any(subset_string in file for subset_string in subset_strings)]\n",
    "    \n",
    "    for infile in infiles:\n",
    "        if os.path.exists(infile):\n",
    "            file_name = os.path.basename(infile).replace('deterministic_hourly_NorthAmerica_','') # Make the name more similar to ERA5_YYYY-MM.nc\n",
    "            outfile = raw_fold/file_name\n",
    "            cs.extract_ERA5_subset(infile,outfile,coords_eme)\n",
    "        else:\n",
    "            print(f'    ERROR: source file {infile} not found.')\n",
    "    \n",
    "    # Create a figure to check if we actually cover the right domain with this\n",
    "    fig_file = raw_fold.parent / f'{row.Country}_{row.Station_id}_em_earth_coverage.png'\n",
    "    cs.compare_forcing_data_and_shape_extents(fig_file, outfile, shp_lump_path, nc_var='tmean', nc_time=0)\n",
    "\n",
    "print(debug_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35587cb7-7d05-43f8-b9e3-29d9fa4b8927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "520d1499-5d1d-4a22-980f-d4fa49e42426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51eb57dc-105d-4111-96de-d55f0edf4970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-70.43208333,  45.98541667, -68.07125   ,  47.83791667])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f762a1fb-e74d-4c82-be34-fe3d20bc2c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([45.985416666666666, 47.837916666666665], [-70.43208333333334, -68.07125])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract values\n",
    "lon = [bounds[0],bounds[2]]\n",
    "lat = [bounds[1],bounds[3]]\n",
    "(lat,lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e421e04a-2f23-40f3-9834-8ac6d6787cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([45.95, 47.85], [-70.45, -68.05])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round to EM-Earth 0.10 degree resolution\n",
    "rounded_lon = [math.floor(lon[0]*20)/20, math.ceil(lon[1]*20)/20]\n",
    "rounded_lat = [math.floor(lat[0]*20)/20, math.ceil(lat[1]*20)/20]\n",
    "(rounded_lat,rounded_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77ee3076-44f4-4946-92bf-88a1725f5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if we are still in the representative area of a different EM-Earth grid cell\n",
    "if lat[0] > rounded_lat[0]+0.05:\n",
    "    rounded_lat[0] += 0.10\n",
    "if lon[0] > rounded_lon[0]+0.05:\n",
    "    rounded_lon[0] += 0.10\n",
    "if lat[1] < rounded_lat[1]-0.05:\n",
    "    rounded_lat[1] -= 0.10\n",
    "if lon[1] < rounded_lon[1]-0.05:\n",
    "    rounded_lon[1] -= 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc321d68-e3c3-43a1-b80d-f0d60d37bf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([45.95, 47.85], [-70.45, -68.05])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rounded_lat,rounded_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d226dae-8a6d-487f-8996-d0180fcae0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d61276b1-39a6-4d98-beeb-3c0d05d3e462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('47.8/-70.4/46.0/-68.1', [46.0, 47.8], [-70.4, -68.1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_download_coords_from_bounds(bounds, target='EM-Earth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6649bee2-ea69-468e-bc7b-127f62c9e0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.ceil(bounds[3]*10)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8745b1-6f49-48fd-bb50-478396c78dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "484d554d-e295-4ca5-a0dc-d51a97c394bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_download_coords_from_bounds(coords, target='ERA5'):\n",
    "    \n",
    "    '''\n",
    "    Determines download coordinates from shapefile bounds for a given data set.\n",
    "    Assumes coodinates are an array: [lon_min, lat_min, lon_max, lat_max] (bottom-left, top-right).\n",
    "    Returns separate lat and lon vectors.\n",
    "    '''\n",
    "\n",
    "    # Source: https://github.com/CH-Earth/CWARHM/blob/main/3a_forcing/1a_download_forcing/download_ERA5_pressureLevel_annual.ipynb   \n",
    "    \n",
    "    # Extract values\n",
    "    lon = [coords[0],coords[2]]\n",
    "    lat = [coords[1],coords[3]]\n",
    "    \n",
    "    if target == 'ERA5':\n",
    "        \n",
    "        # Round to ERA5 0.25 degree resolution\n",
    "        rounded_lon = [math.floor(lon[0]*4)/4, math.ceil(lon[1]*4)/4]\n",
    "        rounded_lat = [math.floor(lat[0]*4)/4, math.ceil(lat[1]*4)/4]\n",
    "\n",
    "        # Find if we are still in the representative area of a different ERA5 grid cell\n",
    "        if lat[0] > rounded_lat[0]+0.125:\n",
    "            rounded_lat[0] += 0.25\n",
    "        if lon[0] > rounded_lon[0]+0.125:\n",
    "            rounded_lon[0] += 0.25\n",
    "        if lat[1] < rounded_lat[1]-0.125:\n",
    "            rounded_lat[1] -= 0.25\n",
    "        if lon[1] < rounded_lon[1]-0.125:\n",
    "            rounded_lon[1] -= 0.25\n",
    "    \n",
    "    if target == 'EM-Earth':\n",
    "        \n",
    "        # Round to EM-Earth 0.10 degree resolution\n",
    "        rounded_lon = [math.floor(lon[0]*20)/20, math.ceil(lon[1]*20)/20]\n",
    "        rounded_lat = [math.floor(lat[0]*20)/20, math.ceil(lat[1]*20)/20]\n",
    "\n",
    "        # Find if we are still in the representative area of a different ERA5 grid cell\n",
    "        if lat[0] > rounded_lat[0]+0.05:\n",
    "            rounded_lat[0] += 0.10\n",
    "        if lon[0] > rounded_lon[0]+0.05:\n",
    "            rounded_lon[0] += 0.10\n",
    "        if lat[1] < rounded_lat[1]-0.05:\n",
    "            rounded_lat[1] -= 0.10\n",
    "        if lon[1] < rounded_lon[1]-0.05:\n",
    "            rounded_lon[1] -= 0.10\n",
    "    \n",
    "    # Make a download string ready for ERA5 (cdsapi) format\n",
    "    dl_string = '{}/{}/{}/{}'.format(rounded_lat[1],rounded_lon[0],rounded_lat[0],rounded_lon[1])\n",
    "    \n",
    "    return dl_string, rounded_lat, rounded_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db2fdad8-0ff6-44c0-93ef-55038a20907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eme = xr.open_dataset(em_earth_files[0])\n",
    "eme = xr.open_dataset(raw_fold/'EM_Earth_1950-01.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54a26f84-d00e-4a4b-850c-1e874d2f1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "eme.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7842f7-c7f7-4dee-a9e3-22b91a49faf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2459cbe-b23b-4f6a-9b9a-6d6af46fed54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2676b7-8597-4416-97d7-46b8d61a4a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac2f282b-94ab-429b-8bb3-b4da9573820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19757f53-4287-4f55-9a20-2f6eef872101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_EM_Earth_subset(infile, outfile, coords):\n",
    "    \n",
    "    '''Subsets an existing EM-Earth forcing file by coordinates \"latmax / lonmin / latmin / lonmax\"'''\n",
    "\n",
    "    # Modified from: https://github.com/CH-Earth/CWARHM/blob/main/0_tools/ERA5_subset_forcing_file_by_lat_lon.py\n",
    "\n",
    "    # Notes:\n",
    "    # 1. Works for North American continent\n",
    "    # 2. Works for two specific ERA5 file layouts\n",
    "\n",
    "    # Assumptions\n",
    "    # 1. Latitude = [-90,90]\n",
    "    # 2. Longitude = [-180,180]\n",
    "    \n",
    "    # Split coordinates\n",
    "    coords = coords.split('/') # split string\n",
    "    coords = [float(value) for value in coords] # string to array\n",
    "    latmax = coords[0]\n",
    "    lonmin = coords[1]\n",
    "    latmin = coords[2]\n",
    "    lonmax = coords[3]\n",
    "    \n",
    "    with xr.open_dataset(infile) as ds:\n",
    "\n",
    "        # Handle specific cases\n",
    "        if (ds['longitude'] > 180).any(): # convert ds longitude form 0/360 to -180/180\n",
    "            lon = ds['longitude'].values\n",
    "            lon[lon > 180] = lon[lon > 180] - 360\n",
    "            ds['longitude'] = lon\n",
    "        \n",
    "        if (ds['latitude'] > 90).any(): # convert ds longitude form 0/180 to -90/90\n",
    "            lat = ds['latitude'].values\n",
    "            lat[lat > 90] = lat[lat > 90] - 180\n",
    "            ds['latitue'] = lat\n",
    "\n",
    "        # Subset\n",
    "        ds_sub = ds.sel(latitude = slice(latmax, latmin), longitude = slice(lonmin, lonmax))\n",
    "        ds_sub.to_netcdf(outfile)\n",
    "        ds_sub.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camels-spat-env",
   "language": "python",
   "name": "camels-spat-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
