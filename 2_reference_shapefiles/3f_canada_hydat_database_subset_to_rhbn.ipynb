{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b308c8ac",
   "metadata": {},
   "source": [
    "# Subset Canada HYDAT database to RHBN 2020 stations\n",
    "The full HYDAT database is 1.1 GB. Subsetting sasves disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec73ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "import python_cs_functions as cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73793dff",
   "metadata": {},
   "source": [
    "### Config handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd4a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where the config file can be found\n",
    "config_file = '../0_config/config.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4855e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the required info from the config file\n",
    "data_path = cs.read_from_config(config_file,'data_path')\n",
    "shps_path = cs.read_from_config(config_file,'ref_shps_path')\n",
    "hydat_url = cs.read_from_config(config_file,'can_hydat_db_url')\n",
    "rhbn_meta = cs.read_from_config(config_file,'can_rhbn_meta_url')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51e3ac2",
   "metadata": {},
   "source": [
    "### Define data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa8ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the download location\n",
    "data_folder = Path(data_path) / shps_path / 'RHBN-CAN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3830949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the HYDAT database. Assumes only 1 sqlite3 database exists\n",
    "hydat_db_name = sorted(data_folder.glob('*.sqlite3'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "261976aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the file name\n",
    "hydat_csv_name = hydat_url.split('/')[-1].strip().replace('.zip','_RHBN_2020_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "929785e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the file name: Get the last part of the url, strip whitespace and characters, replace extension\n",
    "meta_name = rhbn_meta.split('/')[-1].strip().replace('xlsx','csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c13341",
   "metadata": {},
   "source": [
    "### Subset HYDAT database to RHBN 2020 basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddca6e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the RHBN 2020 list\n",
    "df = pd.read_csv(str(data_folder/meta_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74966da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open database\n",
    "db = cs.connect_to_sqlite_database(data_folder/hydat_db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54ab70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search terms for the databse query\n",
    "# See code section below for tests used to find these names and the correct format for value\n",
    "table  = 'STATIONS' \n",
    "field  = 'STATION_NUMBER' \n",
    "values = df['STATION_NUMBER'].tolist() # Get the station IDs as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5d4a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the SQL query we need\n",
    "query = cs.construct_query_from_dataframe_column('STATIONS', 'STATION_NUMBER', values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdef2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the RHBN station metadata from the HYDAT database as a dataframe\n",
    "rhbn = cs.sql_query_to_dataframe(db, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a29ba8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 entries matching one of 1027 Reference Hydrometric Basins\n"
     ]
    }
   ],
   "source": [
    "# Check how many of the basins we have data for\n",
    "print('Found {} entries matching one of {} Reference Hydrometric Basins'.format(len(rhbn),len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96658ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the reduced dataframe as csv\n",
    "rhbn.to_csv(data_folder/hydat_csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5a66592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e7b2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll keep the larger database for the moment, because we want to get flow observations out of it later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a4d5ad",
   "metadata": {},
   "source": [
    "### Database checks\n",
    "Code used during development of the HYDAT functions. Kept for traceability reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96507887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('STATIONS',)\n",
      "('CONCENTRATION_SYMBOLS',)\n",
      "('SED_SAMPLES_PSD',)\n",
      "('ANNUAL_INSTANT_PEAKS',)\n",
      "('STN_DATUM_UNRELATED',)\n",
      "('DATA_SYMBOLS',)\n",
      "('SED_VERTICAL_LOCATION',)\n",
      "('STN_DATA_COLLECTION',)\n",
      "('PEAK_CODES',)\n",
      "('SED_DATA_TYPES',)\n",
      "('MEASUREMENT_CODES',)\n",
      "('SED_VERTICAL_SYMBOLS',)\n",
      "('DATA_TYPES',)\n",
      "('DLY_FLOWS',)\n",
      "('STN_REMARKS',)\n",
      "('STN_DATUM_CONVERSION',)\n",
      "('AGENCY_LIST',)\n",
      "('SED_DLY_SUSCON',)\n",
      "('STN_OPERATION_SCHEDULE',)\n",
      "('STN_DATA_RANGE',)\n",
      "('PRECISION_CODES',)\n",
      "('SED_DLY_LOADS',)\n",
      "('DLY_LEVELS',)\n",
      "('OPERATION_CODES',)\n",
      "('STN_REGULATION',)\n",
      "('DATUM_LIST',)\n",
      "('ANNUAL_STATISTICS',)\n",
      "('VERSION',)\n",
      "('REGIONAL_OFFICE_LIST',)\n",
      "('SAMPLE_REMARK_CODES',)\n",
      "('STN_REMARK_CODES',)\n",
      "('SED_SAMPLES',)\n",
      "('STN_STATUS_CODES',)\n"
     ]
    }
   ],
   "source": [
    "# list the available tables\n",
    "tables = cs.find_all_table_names(db) # -> we want 'STATIONS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d6930b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STATION_NUMBER', 'STATION_NAME', 'PROV_TERR_STATE_LOC', 'REGIONAL_OFFICE_ID', 'HYD_STATUS', 'SED_STATUS', 'LATITUDE', 'LONGITUDE', 'DRAINAGE_AREA_GROSS', 'DRAINAGE_AREA_EFFECT', 'RHBN', 'REAL_TIME', 'CONTRIBUTOR_ID', 'OPERATOR_ID', 'DATUM_ID']\n"
     ]
    }
   ],
   "source": [
    "# Find the headers in the STATION table\n",
    "table_name = 'STATIONS'\n",
    "headers = cs.find_table_headers(db,table_name) # -> we need to subset on 'STATION_NUMBER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa84ddfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('01AA002',\n",
       " 'DAAQUAM (RIVIERE) EN AVAL DE LA RIVIERE SHIDGEL',\n",
       " 'QC',\n",
       " '6',\n",
       " 'D',\n",
       " None,\n",
       " 46.557498931884766,\n",
       " -70.08110809326172,\n",
       " 598.0,\n",
       " None,\n",
       " 0,\n",
       " 0,\n",
       " 740,\n",
       " 740,\n",
       " 405)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the contents of a single row to find which format we need to specify STATION_NUMBER in\n",
    "contents = cs.find_table_contents(db,'STATIONS',to_screen=False)\n",
    "contents[0] # -> we need to specify station IDs as '01AA002' INCLUDING the apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41a602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camels-spat-env",
   "language": "python",
   "name": "camels-spat-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
